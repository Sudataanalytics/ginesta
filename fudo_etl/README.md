# Proyecto ETL para Grupo Ginesta (Datos Gastron√≥micos Fudo)

Este repositorio contiene la soluci√≥n de Extracci√≥n, Transformaci√≥n y Carga (ETL) desarrollada para Grupo Ginesta, con el objetivo de centralizar y procesar los datos de sus unidades gastron√≥micas que utilizan el sistema **Fu.do**.

La soluci√≥n extrae datos crudos de la API de Fu.do, los almacena en una base de datos PostgreSQL, los transforma en un modelo relacional optimizado (DER), y automatiza su actualizaci√≥n para el consumo de Power BI.

---

## üöÄ **Visi√≥n General de la Soluci√≥n**

El ETL procesa datos de ventas, √≠tems de venta, pagos, productos, categor√≠as y sucursales de Fu.do para todas las unidades gastron√≥micas (Nebraska, Quito, Punto Criollo, Chal√©).

**Componentes Clave:**
- **Origen de Datos:** Fu.do API (m√∫ltiples sucursales).
- **Base de Datos de Destino:** PostgreSQL en Donweb (`ginesta` DB).
- **Capas de Datos:**
    - **RAW Layer:** Tablas `fudo_raw_*` (datos crudos, optimizados para cambios de contenido).
    - **Analytic Layer (DER):** Vistas Materializadas `mv_*` (modelo relacional optimizado para Power BI).
- **Orquestaci√≥n:** Python script (`main.py`) dockerizado.
- **Plataforma Cloud:** Google Cloud Platform (GCP) - Cloud Run Jobs, Cloud Scheduler, Secret Manager.
- **Consumo:** Microsoft Power BI (via Power BI Gateway a Donweb).

---

## üèóÔ∏è **Estructura del Proyecto**
grupo ginesta/
‚îú‚îÄ‚îÄ .github/
‚îÇ ‚îî‚îÄ‚îÄ workflows/ # GitHub Actions (futuro CI/CD)
‚îú‚îÄ‚îÄ .gitignore # Archivos ignorados por Git
‚îú‚îÄ‚îÄ fudo_etl/ # Contenedor del ETL de Fu.do
‚îÇ ‚îú‚îÄ‚îÄ modules/ # M√≥dulos Python internos (config, db, auth, api_client, metadata)
‚îÇ ‚îÇ ‚îú‚îÄ‚îÄ init.py
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ ...
‚îÇ ‚îú‚îÄ‚îÄ sql/ # Scripts SQL para despliegue de estructura
‚îÇ ‚îÇ ‚îî‚îÄ‚îÄ deploy_fudo_structure.sql
‚îÇ ‚îú‚îÄ‚îÄ main.py # Script principal del ETL (Extract, Load, Transform)
‚îÇ ‚îú‚îÄ‚îÄ deploy_db.py # Script para la creaci√≥n inicial de la DB en Donweb
‚îÇ ‚îú‚îÄ‚îÄ Dockerfile # Definici√≥n de la imagen Docker para el ETL
‚îÇ ‚îî‚îÄ‚îÄ requirements.txt # Dependencias de Python
‚îú‚îÄ‚îÄ brie-etl/ # Futura integraci√≥n para Minimercados Brie (estructura similar)
‚îÇ ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ venv/ # Entorno virtual (ignorada)
‚îú‚îÄ‚îÄ .env # Variables de entorno locales (ignorada - ¬°CR√çTICO!)
‚îî‚îÄ‚îÄ README.md # Este documento
code
Code
---

## ‚öôÔ∏è **Configuraci√≥n y Despliegue**

### **1. Entorno de Desarrollo Local**

Para ejecutar el ETL localmente (contra tu PostgreSQL local o Donweb para pruebas):

1.  **Clonar el Repositorio:**
    git clone https://github.com/Sudataanalytics/ginesta.git
    cd ginesta

2.  **Crear y Activar Entorno Virtual:**
    python3 -m venv venv
    source venv/bin/activate  # macOS/Linux
 
3.  **Instalar Dependencias:**
    
    pip install -r fudo_etl/requirements.txt

4.  **Configurar `.env`:**
    Crea un archivo `.env` en la **ra√≠z del proyecto** (`grupo ginesta/`) con las credenciales (¬°no lo subas a Git!):
    ```
    DB_CONNECTION_STRING="postgresql://fudo_user:mysecretpassword@localhost:5432/fudo_etl_db"
    DONWEB_ADMIN_CONNECTION_STRING="postgresql://sudata_owner:6w3zAQa4sXs6z@vps-4657831-x.dattaweb.com:5432/postgres"
    TARGET_DATABASE_NAME="ginesta" # O el nombre de tu DB local para pruebas
    FUDO_AUTH_ENDPOINT="https://auth.fu.do/api"
    FUDO_API_BASE_URL="https://api.fu.do"
    GCP_PROJECT_ID="local-dev-project" # ID de tu proyecto GCP, o dummy para local

    # Credenciales de Fu.do (todas las sucursales)
    FUDO_CHALE_APIKEY="MUAxNTk0MzM="
    FUDO_CHALE_APISECRET="oHxOKeifSqdOMt6nICBuOJHsBq4ZfBsA"
    FUDO_QUITO_BAR_APIKEY="..."
    FUDO_QUITO_BAR_APISECRET="..."
    FUDO_NEBRASKA_SAS_APIKEY="..."
    FUDO_NEBRASKA_SAS_APISECRET="..."
    FUDO_PUNTO_CRIOLLO_APIKEY="..."
    FUDO_PUNTO_CRIOLLO_APISECRET="..."
    ```
5.  **Preparar Base de Datos PostgreSQL (Local o Donweb):**
    *   **Local:** Aseg√∫rate de tener PostgreSQL ejecut√°ndose y una DB `fudo_etl_db` con el usuario `fudo_user`.
    *   **Donweb:** Si apuntas a Donweb, aseg√∫rate de que la DB `ginesta` exista y que tu IP local est√© en el firewall.

### **2. Ejecuci√≥n Local del ETL**

**Para crear la DB `ginesta` en Donweb (¬°SOLO UNA VEZ!):**
(Aseg√∫rate de que `DONWEB_ADMIN_CONNECTION_STRING` en `.env` apunte a la DB `postgres` de Donweb).
```bash
python -m fudo_etl.deploy_db
Para desplegar la estructura de tablas/vistas en la DB ginesta (¬°SOLO UNA VEZ por DB!):
(Aseg√∫rate de que DB_CONNECTION_STRING en .env apunte a la DB ginesta de Donweb o tu DB local).
code
Bash
python -m fudo_etl.main # Esto ejecutar√° la fase de despliegue y luego la ETL RAW/Transformaci√≥n
Para ejecuciones regulares (Extracci√≥n y Transformaci√≥n):
(Aseg√∫rate de que DB_CONNECTION_STRING en .env apunte a la DB ginesta de Donweb o tu DB local).
code
Bash
# Comentar la secci√≥n de despliegue de estructura en fudo_etl/main.py
# Y luego ejecutar:
python -m fudo_etl.main
‚òÅÔ∏è Despliegue en Google Cloud Platform (GCP)
1. Configuraci√≥n de GCP
Proyecto: ginestafudo
Regi√≥n: us-central1 (para Cloud Run Jobs, Artifact Registry, Cloud Scheduler).
Habilitar APIs:
Cloud Build API, Cloud Run API, Secret Manager API, Cloud Scheduler API, Artifact Registry API, Cloud Storage API, IAM API.
Crear Secretos en Secret Manager:
Crea un secreto para cada variable mapeada en fudo_etl/cloudbuild.yaml (--set-secrets). Los nombres de los secretos deben ser exactos (ej. fudo-chale-apikey, donweb-db-connection-string, gcp-project-id con valor ginestafudo).
Configurar Repositorio de Artifact Registry:
Crea un repositorio Docker llamado ginesta-fudo-etl-repo en la regi√≥n us-central1.
Configurar Permisos de Cuentas de Servicio:
Cloud Build Service Account ([PROJECT_NUMBER]-compute@developer.gserviceaccount.com):
Administrador de Cloud Run
Usuario de cuenta de servicio
Accesor de secretos de Secret Manager
Escritor de Artifact Registry
Escritor de registros (Logs Writer)
Lector de im√°genes de Container Registry (si a√∫n hubiera necesidad de leer de gcr.io)
Cloud Run Job Service Account (la misma que Cloud Build en este proyecto):
Accesor de secretos de Secret Manager
Invocador de Cloud Run (Este se a√±ade a la SA que dispara el Scheduler, pero si el Job se invoca a s√≠ mismo o se usa esta SA, tambi√©n lo necesita).
2. Disparador de Cloud Build (CI/CD)
Configurar Disparador:
En Cloud Build > Disparadores, crea/edita el disparador ginesta-fudo-etl-deployment-trigger.
Repositorio: Sudataanalytics/ginesta (GitHub).
Rama: main.
Archivo de configuraci√≥n de Cloud Build: fudo_etl/cloudbuild.yaml (¬°ruta correcta dentro del repo!).
Cuenta de Servicio: 595327888136-compute@developer.gserviceaccount.com (la que configuraste con todos los permisos).
Ejecutar Disparador:
Haz un git push a main, o ejecuta manualmente el disparador para desplegar el ginesta-fudo-etl-job.
3. Programaci√≥n con Cloud Scheduler
Crear Tarea:
En Cloud Scheduler, crea la tarea ginesta-fudo-etl-scheduler.
Regi√≥n: us-central1.
Frecuencia: 0 8-23/2 * * * (Cada 2 horas, de 8 AM a 11 PM).
Zona Horaria: America/Argentina/Buenos_Aires.
Objetivo: Cloud Run.
Servicio de Cloud Run: Selecciona ginesta-fudo-etl-job (y su regi√≥n us-central1).
Autenticaci√≥n: OIDC token con la cuenta de servicio 595327888136-compute@developer.gserviceaccount.com (o la que tenga Cloud Run Invoker).
‚úÖ Validaci√≥n Final
Ejecutar Cloud Run Job Manualmente: Desde Cloud Run > Trabajos, haz clic en ginesta-fudo-etl-job y luego en "Ejecutar".
Monitorear Logs: En Cloud Logging, filtra por Resource: Cloud Run Job, ginesta-fudo-etl-job. Verifica que el ETL se ejecute de principio a fin sin errores.
Verificar DB en Donweb: Con pgAdmin, conecta a ginesta y verifica las tablas fudo_raw_* y mv_* para confirmar que los datos se est√°n actualizando.
üìä Integraci√≥n con Power BI
Una vez que el ETL est√© operando en GCP y actualizando Donweb:
Configurar Power BI Gateway: En un servidor de la empresa, instala y configura el On-premises Data Gateway. Crea una fuente de datos PostgreSQL que apunte a vps-4657831-x.dattaweb.com:5432/ginesta con las credenciales de sudata_owner.
Publicar .pbix: La BA publicar√° el GrupoGinesta_Gastronomia_Dashboard_V1.pbix en Power BI Service.
Configurar Actualizaci√≥n Programada: En Power BI Service, en la configuraci√≥n del conjunto de datos, asocia la fuente de datos con el Gateway y configura la actualizaci√≥n cada 2 horas (coincidiendo con el Scheduler).